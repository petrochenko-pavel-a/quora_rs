#char and word vocabularies
num_words: 200000
num_chars: 200

#char and word max sequence meta
max_words_seq: 50
max_chars_seq: 150


#List of word embeddings that should be used
embeddings:
  - glove.840B.300d.txt
  - wiki-news-300d-1M.vec
  - paragram_300_sl999.txt
  - GoogleNews-vectors-negative300.bin
#  - name: custom.vect
#    size: 150
#    window: 4
#    min_count: 2

#dimension of character embedding
dim_char_embedding: 100

###seeds folds and hold out
holdout: 0.2
holdout_seed: 211
folds: 5
folds_seed: 33
stratify_folds: true

model:
  words_dropout: 0.2
  words_dropout_kind: spatial
  has_len: true
  branches:

     gf:
        type: global_features_network
        input: words
        dropout: 0.0
        output_channels: 64
        mode: both

#     cnn:
#        type: cnn
#        input: words
#        channels: [100,50,20]
#        pooling: [1,2,2]
#        windows: [1,2,2]
#        dropout: 0.0
#        mode: dense
#        output_channels: 10
#     lstm:
#       type: lstm
#       input: chars
#       channels: [100,100]
#       dropout: 0.0
#       output_channels: 100

     gru:
        type: residual_gru_with_attention
        input: words
        channels: 100
        last_layer_channels: 50
        output_channels: 30
        dropout: 0.0

optimizer: adam
metrics: ['accuracy']
loss: binary_crossentropy
epochs: 5
batch: 1024